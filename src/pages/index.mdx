---
layout: ../layouts/Layout.astro
title: "Proxies for Distortion and Consistency with Applications for Real-World Image Restoration" 
description: Solve inverse problems with latent diffusion models by mimicking degradations in the latent space
favicon: face.svg
thumbnail: thumbnail.png
---

import Layout from "../layouts/Layout.astro";
import '@iconify-json/simple-icons';


import Header from "../components/Header.astro";
import Video from "../components/Video.astro";
import HighlightedSection from "../components/HighlightedSection.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Figure from "../components/Figure.astro";
import Image from "../components/Image.astro";
import TwoColumns from "../components/TwoColumns.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import LaTeX from "../components/LaTeX.astro";
import ImageComparison from "../components/ImageComparison.astro";

{/* images */}
import hero_fig from "../assets/hero_fig.png";
import est_acc from "../assets/est_acc.png";
import est_realworld from "../assets/est_realworld.png";
import alg from "../assets/alg.png";
import prox from "../assets/prox.png";
import wider_deg from "../assets/0011_wider_degraded.png";
import wider_elad from "../assets/0011_wider_elad.png";
import webphoto_deg from "../assets/00050_02_webphoto_degraded.png";
import webphoto_elad from "../assets/00050_02_webphoto_elad.png";
import lfw_deg from "../assets/Jan_Ullrich_0001_00_lfw_degraded.png";
import lfw_elad from "../assets/Jan_Ullrich_0001_00_lfw_elad.png";

import CodeBlock from "../components/CodeBlock.astro";
import Table from "../components/Table.astro";
export const components = {pre: CodeBlock, table: Table}

<Header
  title={frontmatter.title}
  authors={[
    {
      name: "Sean Man",
      url: "https://scholar.google.com/citations?user=VRCALiIAAAAJ&hl=en",
      institution: "Technion",
    },
    {
      name: "Guy Ohayon",
      url: "https://scholar.google.com/citations?user=Gso71ogAAAAJ&hl=en",
      institution: "Technion",
    },
    {
      name: "Ron Raphaeli",
      url: "https://scholar.google.com/citations?user=kJeQaucAAAAJ&hl=en",
      institution: "Technion",
    },
    {
      name: "Michael Elad",
      url: "https://elad.cs.technion.ac.il/",
      institution: "Technion",
    },
  ]}
  conference=""
  notes={[
      {/* {
        symbol: "*",
        text: "author note one",
      },
      {
        symbol: "†",
        text: "author note two",
      }, */}
    ]}
  links={[
    /* {
      name: "Paper (soon)",
      url: "",
      icon: "fa-solid:file-pdf",
    }, */
    {
      name: "Paper (PDF)",
      url: "https://drive.google.com/file/d/1UVNQtwfkjtKPgVl9paKRhojquOGIPD86/view?usp=share_link",
      icon: "fa-solid:file-pdf",
    },
    {
      name: "Code (soon)",
      url: "",
      icon: "mdi:github",
    },
    {
      name: "HF demo (soon)",
      url: "",
      icon: "simple-icons:huggingface",
    },
  ]}
  />

<HighlightedSection>
<center>
  **tl;dr:** a framework for designing and evaluating real-world image restoration algorithms, including a degradation estimator, a P&P restoration method, and no-reference proxies for MSE and LPIPS
</center>
</HighlightedSection>

<Figure caption="Example restorations of real-world images from WIDER, WebPhoto and LFW datasets using ELAD">
    <ImageComparison
        beforeImage={wider_deg}
        afterImage={wider_elad}
        beforeLabel="Degraded"
        afterLabel="Restored"
    />
    <ImageComparison
        beforeImage={webphoto_deg}
        afterImage={webphoto_elad}
        beforeLabel="Degraded"
        afterLabel="Restored"
    />
    <ImageComparison
        beforeImage={lfw_deg}
        afterImage={lfw_elad}
        beforeLabel="Degraded"
        afterLabel="Restored"
    />
</Figure>

{/* <Image source={hero} altText="hero fig"/> */}

<HighlightedSection>

<TwoColumns>
  <div slot="left" style="text-align: justify;">
    ## Abstract

    Real-world image restoration deals with the recovery of images suffering from an unknown degradation.
    This task is typically addressed while being given only degraded images, without their corresponding ground-truth versions.
    In this hard setting, designing and evaluating restoration algorithms becomes highly challenging.
    This paper offers a suite of tools that can serve both the design and assessment of real-world image restoration algorithms.
    Our work starts by proposing a trained model that predicts the chain of degradations a given real-world measured input has gone through.
    We show how this estimator can be used to approximate the consistency – the match between the measurements and any proposed recovered image.
    We also use this estimator as a guiding force for the design of a simple and highly-effective plug-and-play real-world image restoration algorithm, leveraging a pre-trained diffusion-based image prior.
    Furthermore, this work proposes no-reference proxy measures of MSE and LPIPS, which, without access to the ground-truth images, allow ranking of real-world image restoration algorithms according to their (approximate) MSE and LPIPS.
    The proposed suite provides a versatile, first of its kind framework for evaluating and comparing blind image restoration algorithms in real-world scenarios.
  </div>
  <div slot="right">
    <Figure caption='<p>
  <strong>Paper overview.</strong> We propose 
  <span style="color: blue; border: 1px solid blue; border-radius: 50%; width: 20px; height: 20px; display: inline-flex; justify-content: center; align-items: center; font-size: 14px;">1</span> an estimator that predicts the degradations a real-world input has undergone. Using this, we 
  <span style="color: orange; border: 1px solid orange; border-radius: 50%; width: 20px; height: 20px; display: inline-flex; justify-content: center; align-items: center; font-size: 14px;">2</span> evaluate the consistency of reconstructed candidates and 
  <span style="color: purple; border: 1px solid purple; border-radius: 50%; width: 20px; height: 20px; display: inline-flex; justify-content: center; align-items: center; font-size: 14px;">3</span> develop a plug-and-play restoration algorithm. Finally, we propose 
  <span style="color: green; border: 1px solid green; border-radius: 50%; width: 20px; height: 20px; display: inline-flex; justify-content: center; align-items: center; font-size: 14px;">4</span> no-reference measures of distortion that mimic MSE and LPIPS, eliminating the need for ground-truth images.
</p>
'>
      <Image source={hero_fig} altText="method overview"/>
    </Figure>
  </div>
</TwoColumns>
</HighlightedSection>

## Degradation Estimation
<TwoColumns>
<div slot="left" style="text-align: justify;">
  ### Degradation estimator
  We train a degradation estimator that predicts the parameters of the degradations applied to an image. The estimator achieves high accuracy on blind face degradations, as seen visually from the scatter plots and quantitatively from the R-squared scores.
</div>
<div slot="right">
<Figure caption=''>
      <Image source={est_acc} altText="estimator accuracy"/>
    </Figure>
</div>
</TwoColumns>

<TwoColumns>
<div slot="left" style="text-align: justify;">
  ### Degradations in real-world BFR datasets
  Using our degradation estimator, we reveal the degradations' distribution in real-world datasets. This information can be utilized to better analyze such datasets and mimic them.
 </div>
<div slot="right">
<Figure caption=''>
      <Image source={est_realworld} altText="estimator accuracy"/>
    </Figure>
</div>
</TwoColumns>

<HighlightedSection>

## Plug-and-play Blind Restoration Algorithm

<TwoColumns>
<div slot="left" style="text-align: justify;">
  ### ELAD

  Using the degradation estimator and a pre-trained diffusion model, we construct a blind restoration algorithm.
 We extend prior P&P algorithms such as <a href="https://dps2022.github.io/diffusion-posterior-sampling-page/" target="_blank">DPS</a> to support more general degradations (where the noise is not the last operation) by approximating the likelihood using its first-moment.
</div>
<div slot="right">
<Figure caption=''>
      <Image source={alg} altText="ELAD algorithm"/>
    </Figure>
</div>
</TwoColumns>

</HighlightedSection>

## Proxy MSE & LPIPS

Given a pre-trained MMSE regressor (an <LaTeX inline formula="L_2"/> trained NN), we show how to construct a no-reference distortion measure that mimics the ubiquitous MSE measure. Moreover, by training a simple LPIPS regressor, we construct a similar no-reference measure that mimics LPIPS. Using those measures, we can, for the first time, test the distortion performance of restoration algorithms with no need to access ground-truth data, which is typically unavailable in real-world blind settings.

<Figure caption='<p>
  <strong>Proxy measures accuracy.</strong> The plots compare the proxy measures with their true counterparts, for several state-of-the-art methods evaluated on the synthetic CelebA-Test datasets. A linear regression line is drawn for better clarity. ProxMSE and ProxLPIPS rank methods similarly to the MSE and LPIPS measures without the need for ground-truth images.
</p>
'>
      <Image source={prox} altText="proxy measures" height={2000}/>
    </Figure>


{/* <Figure
    caption="Diagram of the transformer deep learning architecture."
  >
    <Image source={transformer} altText="Diagram of the transformer deep learning architecture." />
</Figure> */}

{/* ## Two columns

Use the two columns component to display two columns of content. In this example, the first column contains a figure with a YouTube video and the second column contains a figure with a custom [React](https://react.dev/) component. By default, they display side by side, but if the screen is narrow enough (for example, on mobile), they're arranged vertically.

<TwoColumns>
  <Figure slot="left" caption="Take a look at this YouTube video.">
    <YouTubeVideo videoId="wjZofJX0v4M" />
  </Figure>
  <Figure slot="right" caption="Now look at this Gaussian Splat, rendered with a React component.">
    <Splat client:idle />
  </Figure>
</TwoColumns>

## Heading levels

Use headings to divide your content into sections.

### Heading 3

Go down a level to heading 3...

#### Heading 4

...and down again to heading 4.

## LaTeX

You can also add LaTeX formulas, rendered during the build process using [KaTeX](https://katex.org/) so they're quick to load for visitors of your project page. You can write them inline, like this: <LaTeX inline formula="a^2 + b^2 = c^2" />. Or, you can write them as a block:

<LaTeX formula="z_T \sim \mathcal{N}(0, I) \text{Encoding:} \space w = \text{clamp}(\mathcal{E}(y),-4,4)" /> */}

{/* ## Tables

You can add simple tables using [GitHub Flavored Markdown syntax](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/organizing-information-with-tables): */}



## BibTeX citation

```bibtex
@article{man2025proxiesdistortionconsistencyapplications,
  title={Proxies for Distortion and Consistency with Applications for Real-World Image Restoration}, 
  author={Sean Man and Guy Ohayon and Ron Raphaeli and Michael Elad},
  year={2025},
  journal={arXiv preprint arXiv:2501.12102},
  url={https://arxiv.org/abs/2501.12102}, 
}
```
