---
layout: ../layouts/Layout.astro
title: "ELAD: Blind Face Restoration using Expectation-based Likelihood Approximation and Diffusion Prior" 
description: Solve inverse problems with latent diffusion models by mimicking degradations in the latent space
favicon: face.svg
thumbnail: thumbnail.png
---

import Layout from "../layouts/Layout.astro";
import '@iconify-json/simple-icons';
import '@iconify-json/academicons';


import Header from "../components/Header.astro";
import Video from "../components/Video.astro";
import HighlightedSection from "../components/HighlightedSection.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Figure from "../components/Figure.astro";
import Image from "../components/Image.astro";
import TwoColumns from "../components/TwoColumns.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import LaTeX from "../components/LaTeX.astro";
import ImageComparison from "../components/ImageComparison.astro";

{/* images */}
import hero_fig from "../assets/hero_fig.png";
import teaser_method from "../assets/teaser-method.png";
import est_acc from "../assets/est_acc.png";
import est_realworld from "../assets/est_realworld.png";
import alg from "../assets/alg.png";
import prox from "../assets/prox.png";
import preliminaries_pixabay from "../assets/preliminaries-pixabay.png";
import wider_deg from "../assets/0011_wider_degraded.png";
import wider_elad from "../assets/0011_wider_elad.png";
import webphoto_deg from "../assets/00050_02_webphoto_degraded.png";
import webphoto_elad from "../assets/00050_02_webphoto_elad.png";
import lfw_deg from "../assets/Jan_Ullrich_0001_00_lfw_degraded.png";
import lfw_elad from "../assets/Jan_Ullrich_0001_00_lfw_elad.png";

import CodeBlock from "../components/CodeBlock.astro";
import Table from "../components/Table.astro";
import BibTeX from "../components/BibTeX.astro";
import InlineMathCaption from "../components/InlineMathCaption.astro";
export const components = {pre: CodeBlock, table: Table}

<Header
  title={frontmatter.title}
  authors={[
    {
      name: "Sean Man",
      url: "https://scholar.google.com/citations?user=VRCALiIAAAAJ&hl=en",
      institution: "Technion",
    },
    {
      name: "Guy Ohayon",
      url: "https://scholar.google.com/citations?user=Gso71ogAAAAJ&hl=en",
      institution: "Technion",
    },
    {
      name: "Ron Raphaeli",
      url: "https://scholar.google.com/citations?user=kJeQaucAAAAJ&hl=en",
      institution: "Technion",
    },
    {
      name: "Matan Kleiner",
      url: "https://scholar.google.com/citations?hl=en&user=n3R271gAAAAJ",
      institution: "Technion",
    },
    {
      name: "Michael Elad",
      url: "https://elad.cs.technion.ac.il/",
      institution: "Technion",
    },
  ]}
  conference="SIGGRAPH Asia 2025"
  notes={[
      {/* {
        symbol: "*",
        text: "author note one",
      },
      {
        symbol: "â€ ",
        text: "author note two",
      }, */}
    ]}
  links={[
    /* {
      name: "Paper (soon)",
      url: "",
      icon: "fa-solid:file-pdf",
    }, */
    {
      name: "Paper",
      url: "https://dl.acm.org/doi/pdf/10.1145/3757377.3763969",
      icon: "academicons:acm",
    },
    {
      name: "Appendix",
      url: "https://dl.acm.org/doi/suppl/10.1145/3757377.3763969/suppl_file/appendix.pdf",
      icon: "academicons:acm",
    },
    {
      name: "Code (soon)",
      url: "",
      icon: "mdi:github",
    },
  ]}
  doi={{
    url: "https://doi.org/10.1145/3757377.3763969",
    text: "10.1145/3757377.3763969",
  }}
  />

<HighlightedSection>
<center>
  **tl;dr:** ELAD is a plug-and-play method for blind face restoration that explicitly models the likelihood with a degradation estimator, enabling principled Bayesian inference and strong distortion/identity metrics without end-to-end training.
</center>
</HighlightedSection>

<Figure caption="Example restorations of real-world images from WIDER, WebPhoto and LFW datasets using ELAD">
    <ImageComparison
        beforeImage={wider_deg}
        afterImage={wider_elad}
        beforeLabel="Degraded"
        afterLabel="Restored"
    />
    <ImageComparison
        beforeImage={webphoto_deg}
        afterImage={webphoto_elad}
        beforeLabel="Degraded"
        afterLabel="Restored"
    />
    <ImageComparison
        beforeImage={lfw_deg}
        afterImage={lfw_elad}
        beforeLabel="Degraded"
        afterLabel="Restored"
    />
</Figure>

{/* <Image source={hero} altText="hero fig"/> */}

<HighlightedSection>
<div style="text-align: justify;">
    ## Abstract

    Blind Face Restoration (BFR) aims to recover face images suffering from unknown degradations.
    A recent approach to solve BFR is via plug-and-play methods for image restoration, which combine a likelihood function with pre-trained diffusion models as priors.
    However, as the likelihood is inherently unknown in BFR, existing methods rely instead on heuristic constraints.
    This leads to suboptimal distortion and identity preservation metrics.
    We introduce Expectation-based Likelihood Approximation with Diffusion prior (ELAD), a novel plug-and-play approach that explicitly models the likelihood function for BFR.
    ELAD estimates the first and second moments of the likelihood distribution by employing a Degradation Estimator to predict the degradation sequence from the input.
    This enables principled Bayesian inference without requiring end-to-end training.
    Our method achieves state-of-the-art distortion and identity preservation results compared to existing plug-and-play BFR techniques, while maintaining competitive perceptual quality.
    As we show, while being plug-and-play, our method still rivals end-to-end trained BFR models.
  </div>
  <Figure caption="<p><strong>Method overview.</strong> ELAD uses a degradation estimator to model the likelihood and enables principled plug-and-play restoration.</p>">
    <Image source={teaser_method} altText="method overview"/>
  </Figure>
</HighlightedSection>

## Problem overview
Real-world blind face restoration observes only a degraded measurement <LaTeX inline formula="y" />, produced by an unknown sequence of degradations applied to a clean image <LaTeX inline formula="x" />. Our goal is to sample restored images <LaTeX inline formula="\\hat{x}" /> that are consistent with the measurements while maintaining high perceptual quality.

<Figure caption="<p>Problem setup overview.</p>">
  <Image source={preliminaries_pixabay} altText="problem overview"/>
</Figure>
<InlineMathCaption
  text={String.raw`(top) A clean image $x$ undergoes a sequence of blur, down-sampling, noising, and compression-decompression operations with unknown parameters $a$ to create the observed degraded measurement $y$. (bottom) Given $y$, we aim to sample images $\hat{x}$ from the posterior $p_{X\mid Y,A}$, each consistent with the measurements and with high perceptual quality.`}
/>

<HighlightedSection>

## Plug-and-play Blind Restoration Algorithm

<TwoColumns>
<div slot="left" style="text-align: justify;">
  Using the degradation estimator and a pre-trained diffusion model, we construct a blind restoration algorithm.
 We extend prior P&P algorithms such as <a href="https://dps2022.github.io/diffusion-posterior-sampling-page/" target="_blank">DPS</a> to support more general degradations (where the noise is not the last operation) by approximating the likelihood using its first-moment.
</div>
<div slot="right">
<Figure caption=''>
      <Image source={alg} altText="ELAD algorithm"/>
    </Figure>
</div>
</TwoColumns>

</HighlightedSection>

## Degradation Estimation
<TwoColumns>
<div slot="left" style="text-align: justify;">
  ### Degradation estimator
  We train a degradation estimator that predicts the parameters of the degradations applied to an image. The estimator achieves high accuracy on blind face degradations, as seen visually from the scatter plots and quantitatively from the R-squared scores.
</div>
<div slot="right">
<Figure caption=''>
      <Image source={est_acc} altText="estimator accuracy"/>
    </Figure>
</div>
</TwoColumns>

<TwoColumns>
<div slot="left" style="text-align: justify;">
  ### Degradations in real-world BFR datasets
  Using our degradation estimator, we reveal the degradations' distribution in real-world datasets. This information can be utilized to better analyze such datasets and mimic them.
 </div>
<div slot="right">
<Figure caption=''>
      <Image source={est_realworld} altText="estimator accuracy"/>
    </Figure>
</div>
</TwoColumns>

## Proxy MSE & LPIPS

Given a pre-trained MMSE regressor (an <LaTeX inline formula="L_2"/> trained NN), we show how to construct a no-reference distortion measure that mimics the ubiquitous MSE measure. Moreover, by training a simple LPIPS regressor, we construct a similar no-reference measure that mimics LPIPS. Using those measures, we can, for the first time, test the distortion performance of restoration algorithms with no need to access ground-truth data, which is typically unavailable in real-world blind settings.

<Figure caption='<p>
  <strong>Proxy measures accuracy.</strong> The plots compare the proxy measures with their true counterparts, for several state-of-the-art methods evaluated on the synthetic CelebA-Test datasets. A linear regression line is drawn for better clarity. ProxMSE and ProxLPIPS rank methods similarly to the MSE and LPIPS measures without the need for ground-truth images.
</p>
'>
      <Image source={prox} altText="proxy measures" height={2000}/>
    </Figure>


{/* <Figure
    caption="Diagram of the transformer deep learning architecture."
  >
    <Image source={transformer} altText="Diagram of the transformer deep learning architecture." />
</Figure> */}

{/* ## Two columns

Use the two columns component to display two columns of content. In this example, the first column contains a figure with a YouTube video and the second column contains a figure with a custom [React](https://react.dev/) component. By default, they display side by side, but if the screen is narrow enough (for example, on mobile), they're arranged vertically.

<TwoColumns>
  <Figure slot="left" caption="Take a look at this YouTube video.">
    <YouTubeVideo videoId="wjZofJX0v4M" />
  </Figure>
  <Figure slot="right" caption="Now look at this Gaussian Splat, rendered with a React component.">
    <Splat client:idle />
  </Figure>
</TwoColumns>

## Heading levels

Use headings to divide your content into sections.

### Heading 3

Go down a level to heading 3...

#### Heading 4

...and down again to heading 4.

## LaTeX

You can also add LaTeX formulas, rendered during the build process using [KaTeX](https://katex.org/) so they're quick to load for visitors of your project page. You can write them inline, like this: <LaTeX inline formula="a^2 + b^2 = c^2" />. Or, you can write them as a block:

<LaTeX formula="z_T \sim \mathcal{N}(0, I) \text{Encoding:} \space w = \text{clamp}(\mathcal{E}(y),-4,4)" /> */}

{/* ## Tables

You can add simple tables using [GitHub Flavored Markdown syntax](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/organizing-information-with-tables): */}



## BibTeX citation
<BibTeX text={`@inproceedings{10.1145/3757377.3763969,
author = {Man, Sean and Ohayon, Guy and Raphaeli, Ron and Kleiner, Matan and Elad, Michael},
title = {ELAD: Blind Face Restoration using Expectation-based Likelihood Approximation and Diffusion Prior},
year = {2025},
isbn = {9798400721373},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3757377.3763969},
doi = {10.1145/3757377.3763969},
booktitle = {Proceedings of the SIGGRAPH Asia 2025 Conference Papers},
articleno = {63},
numpages = {12},
keywords = {Blind Face Restoration, Image Restoration, Plug and Play, Diffusion Prior, Posterior Sampling},
location = {
},
series = {SA Conference Papers '25}
}`}
/>
